/* This file maps various symbols and keywords to the relevent "tokent aliases"
 * The lexer uses these maps to determine which token aliasess go with what
 * symbols
 */
package lexer

import "turtlego/tokens"

var Asm_singleChar = map[string]byte{
	string(EOF): tokens.EOF,
	"\n":        tokens.EOL,
	":":         tokens.COLON,
	".":         tokens.PERIOD,
	",":         tokens.COMMA,
	"+":         tokens.PLUS,
	"-":         tokens.MINUS,
	"(":         tokens.LPAREN,
	")":         tokens.RPAREN,
}

var Asm_keyword = map[string]byte{
	"ddw":   tokens.DDW,
	"dw":    tokens.DW,
	"dhw":   tokens.DHW,
	"db":    tokens.DB,
	"cdw":   tokens.CDW,
	"cw":    tokens.CW,
	"chw":   tokens.CHW,
	"cb":    tokens.CB,
	"ld":    tokens.LD,
	"st":    tokens.ST,
	"call":  tokens.CALL,
	"tail":  tokens.TAIL,
	"ret":   tokens.RET,
	"add":   tokens.ADD,
	"addi":  tokens.ADDI,
	"and":   tokens.AND,
	"andi":  tokens.ANDI,
	"auipc": tokens.AUPIC,
	"beq":   tokens.BEQ,
	"bge":   tokens.BGE,
	"bgeu":  tokens.BGEU,
	"blt":   tokens.BLT,
	"bltu":  tokens.BLTU,
	"bne":   tokens.BNE,
	"jal":   tokens.JAL,
	"jalr":  tokens.JALR,
	"lb":    tokens.LB,
	"lbu":   tokens.LBU,
	"lh":    tokens.LH,
	"lhu":   tokens.LHU,
	"lui":   tokens.LUI,
	"lw":    tokens.LW,
	"or":    tokens.OR,
	"ori":   tokens.ORI,
	"sb":    tokens.SB,
	"sh":    tokens.SH,
	"sll":   tokens.SLL,
	"slli":  tokens.SLLI,
	"slt":   tokens.SLT,
	"sltiu": tokens.SLTIU,
	"sltu":  tokens.SLTU,
	"sra":   tokens.SRA,
	"srai":  tokens.SRAI,
	"srl":   tokens.SRL,
	"srli":  tokens.SRLI,
	"sub":   tokens.SUB,
	"sw":    tokens.SW,
	"xor":   tokens.XOR,
	"xori":  tokens.XORI,

	"x0":  tokens.ZERO_REG,
	"x1":  tokens.RA_REG,
	"x2":  tokens.SP_REG,
	"x3":  tokens.GP_REG,
	"x4":  tokens.TP_REG,
	"x5":  tokens.T0_REG,
	"x6":  tokens.T1_REG,
	"x7":  tokens.T2_REG,
	"x8":  tokens.S0_REG,
	"x9":  tokens.S1_REG,
	"x10": tokens.A0_REG,
	"x11": tokens.A1_REG,
	"x12": tokens.A2_REG,
	"x13": tokens.A3_REG,
	"x14": tokens.A4_REG,
	"x15": tokens.A5_REG,
	"x16": tokens.A6_REG,
	"x17": tokens.A7_REG,
	"x18": tokens.S2_REG,
	"x19": tokens.S3_REG,
	"x20": tokens.S4_REG,
	"x21": tokens.S5_REG,
	"x22": tokens.S6_REG,
	"x23": tokens.S7_REG,
	"x24": tokens.S8_REG,
	"x25": tokens.S9_REG,
	"x26": tokens.S10_REG,
	"x27": tokens.S11_REG,
	"x28": tokens.T3_REG,
	"x29": tokens.T4_REG,
	"x30": tokens.T5_REG,
	"x31": tokens.T6_REG,

	"zero": tokens.ZERO_REG,
	"ra":   tokens.RA_REG,
	"sp":   tokens.SP_REG,
	"gp":   tokens.GP_REG,
	"tp":   tokens.TP_REG,
	"t0":   tokens.T0_REG,
	"t1":   tokens.T1_REG,
	"t2":   tokens.T2_REG,
	"s0":   tokens.S0_REG,
	"s1":   tokens.S1_REG,
	"a0":   tokens.A0_REG,
	"a1":   tokens.A1_REG,
	"a2":   tokens.A2_REG,
	"a3":   tokens.A3_REG,
	"a4":   tokens.A4_REG,
	"a5":   tokens.A5_REG,
	"a6":   tokens.A6_REG,
	"a7":   tokens.A7_REG,
	"s2":   tokens.S2_REG,
	"s3":   tokens.S3_REG,
	"s4":   tokens.S4_REG,
	"s5":   tokens.S5_REG,
	"s6":   tokens.S6_REG,
	"s7":   tokens.S7_REG,
	"s8":   tokens.S8_REG,
	"s9":   tokens.S9_REG,
	"s10":  tokens.S10_REG,
	"s11":  tokens.S11_REG,
	"t3":   tokens.T3_REG,
	"t4":   tokens.T4_REG,
	"t5":   tokens.T5_REG,
	"t6":   tokens.T6_REG,

	"fp": tokens.S0_REG,

	"ebreak": tokens.EBREAK,
}
